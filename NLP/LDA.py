# We take a probabilistic model for documents. Neglecting some of the
# hairier mathematical details:

# There is some fixed number K of topics

# There is a random variable that assigns each topic an associated
# probability distribution over workds. You should think of this
# distribution as a probability of seeing word w given topic k

# There is another random variable that assigns each document a
# probability distribution over topics. You should think of this
# distribution as the mixture of topics in document d

# Each word in a document was generated by first randomly piciking a
# topic (from the document's distribution of topics) and then
# randomly picking a word (from the topic's distribution of words)

# In particular, the fifth word in the fourth document is:
# > documents[3][4]
# and the topic from which that word was chosen is
# > document_topics[3][4]

# Our documents are our users' interests:

documents = [
	["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
	["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
	["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
	["R", "Python", "statistics", "regression", "probability"],
	["machine learning", "regression", "decision trees", "libsvm"],
	["Python", "R", "Java", "C++", "Haskell", "programming languages"],
	["statistics", "probability", "mathematics", "theory"],
	["machine learning", "scikit-learn", "Mahout", "neural networks"],
	["neural networks", "deep learning", "Big Data", "artificial intelligence"],
	["Hadoop", "Java", "MapReduce", "Big Data"],
	["statistics", "R", "statsmodels"],
	["C++", "deep learning", "artificial intelligence", "probability"],
	["pandas", "R", "Python"],
	["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
	["libsvm", "regression", "support vector machines"]
]

# We'll try to find K = 4 topics